---
title: Product Bug Triage & Data Visibility
role: Product Manager, Internal Tools & Product Operations
company: Teachable
dates: 2018 - 2019
tldr: Overhauled prioritization framework, established SLAs, and built dashboards for product, tech leads, and tech support to proactively manage issues and set resolution targets.
tags:
  - Data Visibility
  - Product Operations
  - SQL
  - Looker
  - Stakeholder management
  - Internal Tools
---

## 1. The Goal: Smooth Scaling on Bug Triage

Teachable Product & Engineering consistently shipped quickly, but we lacked a reliable way to understand the health of our bug reporting and resolution process.
What I learned informally from peers in Engineering, Customer Care, and Product was basic, but instructive:

Turns out we couldn't answer basic questions:
- How many bugs did we have?
- How many of them are valid?
- How long do they take to resolve?
- Where were things getting stuck?

Bug reports flowed into Customer Care (CC), then to Product Solutions (PS - a technical support team that vetted bugs), and then out to multiple engineering pods. However: ownership, prioritization, and timelines all lacked consistency. The result was friction between teams, unclear accountability, and complete lack of confidence in the current system.

**My Goal:** Treat Bug Triage as a product and make it measurable.

I launched an initiatve to close the loop on information gaps, and lobbied the VP of Product, CTO, and VP of Engineering to back me up as I rolled out new tooling, behaviors, and overall approach to keeping our bugs squashed, product healthy, and customers ... well, *not* noticing anything was wrong.

## 2. Diagnose Before Design

**My primary stakeholders:**

- Customer Care (intake)
- Product Solutions (technical triage)
- Pod Leads and Engineers (execution)
- Data Team (analytics foundations)

**What I did:**

1. Mapped the end-to-end-workflow
    1. Customer-reported issues -> escalation -> validation -> resolution
    2. identified blockers across handoffs, duplication, ownership confusion

![Bug workflow](/diagrams/teachable-bug-lifecycle.png)

2. Conducted stakeholder interviews
    1. Focused on where context was lost
    1. Where follow-ups became manual
    1. Where trust broke down. From the archives:
        - *"How can I even find out the status of that bug I reported?"*
        - *"I didn't even know we were asked to fix that bug"*
        - *"I wish they would spend more time with customer inquiries before bringing problems to us that aren't actually bugs"*
3. Audited existing data

    etc. etc.

    1. Labeled states, priorities, timelines
    1. Identified drift, inconsistency, and missing information and history

4. Partnered with Data
    1. Defined what data needed to exist before:
        1. Any dashboards or tooling could make a meaningful difference
        1. **Crucially:** We could actually quantifiably assess our gaps as an organization
    1. Prototyped analysis manually to validate questions

## 3. Uncover Silent Systemic Failures

**Key Findings**

- Measurement was impossible 
Labels changed over time, timelines weren't defined consistently, hsitorical data couldn't be trusted

- Ownership was diffused

Engineers weren't sure which tickets to follow. Product Solutions actued as manual workflow guidelines

- Tooling amplified social friction

Duplicate stories, unclear sources of truth, and constant follow-ups eroded confidence

## Metrics Overview

| Metric | Before | After | Change |
| ------ | ------ | ----- | ------ |
| Page load time | 4.2s | 1.1s | −74% |
| Daily active users | 1,200 | 1,680 | +40% |
| Support tickets | 320/mo | 240/mo | −25% |
| Conversion rate | 2.1% | 3.4% | +62% |